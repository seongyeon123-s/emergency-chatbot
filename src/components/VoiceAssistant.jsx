// VoiceAssistant.jsx
import { useEffect, useState, useRef } from "react"

export default function VoiceAssistant({ lang = "ko", onResult, autoStart = false }) {
  const [transcript, setTranscript] = useState("")
  const [listening, setListening] = useState(false)
  const recognitionRef = useRef(null)

  const langMap = {
    ko: "ko-KR",
    en: "en-US",
    zh: "zh-CN",
    ja: "ja-JP",
    es: "es-ES"
  }

  const textMap = {
    ko: {
      title: "ðŸŽ¤ í˜„ìž¬ ë¬´ìŠ¨ ìƒí™©ì¸ê°€ìš”",
      speak: "ë§í•˜ê¸°",
      read: "ì½ì–´ì£¼ê¸°",
      result: "ì¸ì‹ ê²°ê³¼",
      none: "ì—†ìŒ"
    },
    en: {
      title: "ðŸŽ¤ What is the current situation?",
      speak: "Speak",
      read: "Read",
      result: "Result",
      none: "None"
    },
    zh: {
      title: "ðŸŽ¤ å½“å‰æ˜¯ä»€ä¹ˆæƒ…å†µï¼Ÿ",
      speak: "è¯´è¯",
      read: "æœ—è¯»",
      result: "è¯†åˆ«ç»“æžœ",
      none: "æ— "
    },
    ja: {
      title: "ðŸŽ¤ ç¾åœ¨ã®çŠ¶æ³ã¯ä½•ã§ã™ã‹ï¼Ÿ",
      speak: "è©±ã™",
      read: "èª­ã‚€",
      result: "èªè­˜çµæžœ",
      none: "ãªã—"
    },
    es: {
      title: "ðŸŽ¤ Â¿CuÃ¡l es la situaciÃ³n actual?",
      speak: "Hablar",
      read: "Leer",
      result: "Resultado",
      none: "Ninguno"
    }
  }

  useEffect(() => {
    if (!("webkitSpeechRecognition" in window)) {
      alert("ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
      return
    }

    const SpeechRecognition = window.webkitSpeechRecognition
    const recognition = new SpeechRecognition()
    recognition.lang = langMap[lang] || "ko-KR"
    recognition.interimResults = false
    recognition.maxAlternatives = 1
    recognition.continuous = false

    recognition.onstart = () => setListening(true)
    recognition.onend = () => setListening(false)

    recognition.onresult = (event) => {
      const result = event.results[0][0].transcript
      setTranscript(result)
      if (onResult) onResult(result)
    }

    recognition.onerror = (event) => {
      console.error("ðŸŽ¤ ì¸ì‹ ì˜¤ë¥˜:", event.error)
      setListening(false)
    }

    recognitionRef.current = recognition

    if (autoStart) recognition.start()

    return () => recognition.stop()
  }, [lang, autoStart, onResult])

  const startRecognition = () => {
    if (recognitionRef.current && !listening) {
      recognitionRef.current.start()
    }
  }

  const t = textMap[lang] || textMap.ko

  return (
    <div className="mt-4 p-4 bg-gray-100 rounded-lg shadow">
      <h2 className="text-lg font-semibold">{t.title}</h2>
      <div className="mt-2 flex space-x-2">
        <button
          className="bg-blue-500 hover:bg-blue-600 text-white px-4 py-2 rounded"
          onClick={startRecognition}
          disabled={listening}
        >
          {listening ? "..." : t.speak}
        </button>
        <button
          className="bg-green-500 hover:bg-green-600 text-white px-4 py-2 rounded"
          onClick={() => {
            const utterance = new SpeechSynthesisUtterance(t.title.replace("ðŸŽ¤ ", ""))
            utterance.lang = langMap[lang] || "ko-KR"
            window.speechSynthesis.speak(utterance)
          }}
        >
          {t.read}
        </button>
      </div>
      <p className="mt-2 text-sm text-gray-700">ðŸ—£ {t.result}: {transcript || t.none}</p>
    </div>
  )
}
